import asyncio
import pandas as pd
import sys
import io
import random
import os
import requests
from datetime import datetime
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode
from bs4 import BeautifulSoup

# Thi·∫øt l·∫≠p b·∫£ng m√£ cho Terminal Windows
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# --- C·∫§U H√åNH ---
UPCOMING_URL = "https://www.marketindex.com.au/upcoming-dividends"
ASX_URL = "https://www.marketindex.com.au/asx/{}"
# URL Webhook c·ªßa n8n (D√πng host.docker.internal ƒë·ªÉ Docker g·ªçi ƒë∆∞·ª£c m√°y ch·ªß n8n local)
N8N_WEBHOOK_URL = "http://host.docker.internal:5678/webhook-test/asx-data"

def parse_international_date(date_str):
    """Chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng ng√†y sang YYYY-MM-DD."""
    if not date_str or date_str == "N/A":
        return "N/A"
    current_year = datetime.now().year
    try:
        return datetime.strptime(date_str, "%d %b %Y").strftime("%Y-%m-%d")
    except ValueError:
        try:
            return datetime.strptime(f"{date_str} {current_year}", "%d %b %Y").strftime("%Y-%m-%d")
        except:
            return date_str

def clean_to_number(text):
    """X√≥a k√Ω t·ª± ti·ªÅn t·ªá v√† chuy·ªÉn sang s·ªë th·ª±c."""
    if not text or text in ['\u2010', '-', 'N/A', '']:
        return None
    try:
        return float(text.replace(',', '').replace('$', '').replace('%', '').strip())
    except:
        return None

def clean_percent_to_decimal(text):
    """Chuy·ªÉn 100% th√†nh 1.0."""
    val = clean_to_number(text)
    return val / 100 if val is not None else None

async def main():
    results = []
    
    run_config = CrawlerRunConfig(
        cache_mode=CacheMode.BYPASS,
        wait_for="table tbody tr",
        page_timeout=60000,
        js_code="window.scrollTo(0, document.body.scrollHeight/2);", 
        wait_for_images=True
    )

    async with AsyncWebCrawler() as crawler:
        print(f"üåê ƒêang l·∫•y danh s√°ch t·ª´: {UPCOMING_URL}")
        result = await crawler.arun(url=UPCOMING_URL, config=run_config)
        
        if not result.success:
            print(f"‚ùå L·ªói crawl: {result.error_message}")
            return

        soup = BeautifulSoup(result.html, 'html.parser')
        rows = soup.select("table tbody tr")
        print(f"üìä T√¨m th·∫•y {len(rows)} h√†ng ti·ªÅm nƒÉng.")

        for i, row in enumerate(rows):
            try:
                cells = row.find_all("td")
                if not cells: continue

                code = cells[0].get_text(strip=True)
                amount_val = clean_to_number(cells[4].get_text(strip=True))

                # Ch·ªâ l·∫•y nh·ªØng m√£ c√≥ chia c·ªï t·ª©c > 0
                if amount_val is None or amount_val == 0:
                    continue

                company = cells[1].get_text(strip=True)
                ex_date = parse_international_date(cells[3].get_text(strip=True))
                franking = clean_percent_to_decimal(cells[5].get_text(strip=True))
                pay_date = parse_international_date(cells[7].get_text(strip=True))
                yield_val = clean_percent_to_decimal(cells[8].get_text(strip=True))

                # B∆∞·ªõc 2: Truy c·∫≠p trang chi ti·∫øt ƒë·ªÉ l·∫•y Price v√† Volume
                detail_url = ASX_URL.format(code.lower())
                vol_num, price_num = None, None
                
                for attempt in range(2):
                    detail_result = await crawler.arun(
                        url=detail_url,
                        config=CrawlerRunConfig(
                            cache_mode=CacheMode.BYPASS if attempt > 0 else CacheMode.ENABLED,
                            wait_for="span[data-quoteapi='price']",
                            js_code="window.scrollBy(0, 300);"
                        )
                    )

                    if detail_result.success:
                        d_soup = BeautifulSoup(detail_result.html, 'html.parser')
                        vol_elem = d_soup.select_one("span[data-quoteapi*='monthAverageVolume']")
                        price_elem = d_soup.select_one("span[data-quoteapi='price']")
                        
                        vol_num = clean_to_number(vol_elem.get_text(strip=True)) if vol_elem else None
                        price_num = clean_to_number(price_elem.get_text(strip=True)) if price_elem else None
                        
                        if vol_num and price_num:
                            break
                        await asyncio.sleep(4)

                total_value = vol_num * price_num if vol_num and price_num else None
                print(f"‚úÖ [{i+1}] {code:5} | price: {price_num:6} | Vol: {vol_num}")

                # L∆∞u v√†o list k·∫øt qu·∫£
                results.append({
                    "Code": code, "Company": company, "Ex_Date": ex_date,
                    "Amount": amount_val, "Franking": franking, "Pay_Date": pay_date,
                    "Yield": yield_val, "Price": price_num, "Vol_4W": vol_num,
                    "Total_Value": total_value
                })

                # Ngh·ªâ gi·ªØa m·ªói l·∫ßn crawl ƒë·ªÉ tr√°nh b·ªã ch·∫∑n
                await asyncio.sleep(random.uniform(5.0, 6.0))

            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói t·∫°i h√†ng {i}: {e}")

    # --- XU·∫§T D·ªÆ LI·ªÜU ---
    if results:
        # 1. L∆∞u file CSV c·ª•c b·ªô d·ª± ph√≤ng
        if not os.path.exists('output'):
            os.makedirs('output')
            
        df = pd.DataFrame(results)
        file_path = "output/asx_dividends.csv"
        df.to_csv(file_path, index=False, encoding='utf-8-sig')
        print(f"\nüíæ ƒê√£ l∆∞u file d·ª± ph√≤ng t·∫°i: {file_path}")

        # 2. G·ª≠i d·ªØ li·ªáu sang n8n qua Webhook
        print(f"üì° ƒêang g·ª≠i {len(results)} d√≤ng d·ªØ li·ªáu sang n8n...")
        try:
            response = requests.post(
                N8N_WEBHOOK_URL, 
                json=results, 
                headers={"Content-Type": "application/json"},
                timeout=60
            )
            if response.status_code == 200:
                print("üéâ TH√ÄNH C√îNG: n8n ƒë√£ nh·∫≠n d·ªØ li·ªáu!")
            else:
                print(f"‚ùå Th·∫•t b·∫°i: n8n tr·∫£ v·ªÅ m√£ {response.status_code}")
        except Exception as e:
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi n8n: {e}")

if __name__ == "__main__":
    asyncio.run(main())